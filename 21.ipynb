{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5O7OCXU_D_g"
      },
      "outputs": [],
      "source": [
        "#INSTALLATION OF PACKAGES"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF8aJ_cs_Gny",
        "outputId": "f4d29ebb-475f-4a91-b55c-3f4ba782020b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuGSyNg0_H2O",
        "outputId": "63bf953c-7985-4575-e5f4-e11dd49d1c67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/239.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/239.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.5.0)\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install reportlab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87zqsP4m_Jb6",
        "outputId": "cd340a0e-01ae-4f3d-cbcf-803699462433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting reportlab\n",
            "  Downloading reportlab-4.0.7-py3-none-any.whl (1.9 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.9 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.9 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from reportlab) (9.4.0)\n",
            "Installing collected packages: reportlab\n",
            "Successfully installed reportlab-4.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install docx2txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkNPdKis_NLV",
        "outputId": "39fbaa3c-4321-4aad-b63c-bafb9dec7b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=2dff21d06caa136d773a67c8d6ceb4a45207f9cbbf23d6bd15484382537d5942\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt\n",
            "Successfully installed docx2txt-0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z2OcS_o_PpL",
        "outputId": "12f2bd0c-2915-40ba-aff5-2c90a240b45a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/232.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.27.8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUs14n6g_Rdq",
        "outputId": "d7a54794-46d5-4a52-cb08-8d4ce5e25f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.27.8\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.27.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFINING CREDENTIALS FOR OPENAI"
      ],
      "metadata": {
        "id": "LIBCs6u6_TLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "FJ4XckD5_ZDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "KjR4YSXZ_cE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"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\""
      ],
      "metadata": {
        "id": "vs-VwOUT_dnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_promp=\"You are an AI expert in converting the list of dictionaries to the format of correct json data. Avoid unnecessary sentence. Keep the correct output of json data for the given list of dictionaries\"\n",
        "personal_details_promp=\"You are an AI expert in analyzing text extracted from resumes . I need to extract only the candidate's name(For example:SINEGALATHA B), candidate's contact number, candidate's email id, candidate's social media profiles(like linkedin, instagram, github or any portfolio), candidate's area of interest(the technical skills in which he is more interested and technically strong), candidate's technical skills, candidate's interpersonal skills, candidate's achievements, educational details of candidate who have submitted the resume, name of companies where the candidate completed or doing ongoing internships and its details, candidate's previously worked projects, candidate's previously worked experience in companies from extracted text. The output need to be in the format of dictionary with keys {'Name': 'candidate's name', 'Contact Number': candidate's contact number, 'Email Id': candidate's email id, 'Social Media Profile': candidate's social media profiles, 'Area of Interest': candidate's area of interest, 'Technical Skills': candidate's technical skills, 'Interpersonal Skills': candidate's interpersonal skills, 'Achievement': candidate's achievements, 'Educational Details': candidate's Educational details of candidate who have submitted the resume, 'Internships' :name of companies where the candidate completed or doing ongoing internships and its details, 'Previous Worked Projects': candidate's previously worked projects, 'Previous Working Experience':  candidate's previously worked experience in companies}.Avoid unnecessary sentence. Keep only the accurate single word answers. Return only exact dictionary as response. Except the mentioned keys in dictionary do not add any new key pair values.\""
      ],
      "metadata": {
        "id": "J6NO7HTT_fHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REQUEST HANDLER"
      ],
      "metadata": {
        "id": "ZNeIiu6f_giR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def submit_request_gpt(system_prompt,transcription,openai):\n",
        "  response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        temperature=0,\n",
        "        max_tokens=100,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\":system_prompt\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": transcription\n",
        "            }\n",
        "              ]\n",
        "          )\n",
        "  return response['choices'][0]['message']['content']"
      ],
      "metadata": {
        "id": "2gte_kEP_h6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFINING THE FUNCTION TO EXTRACTION OF RESUME"
      ],
      "metadata": {
        "id": "PTYOx2a5_jYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "def extraction(transcription,openai):\n",
        "    personal_details = submit_request_gpt(personal_details_promp,transcription,openai=openai)\n",
        "    print(personal_details)\n",
        "    return personal_details"
      ],
      "metadata": {
        "id": "2-PmIOGM_kvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import ast\n",
        "from docx import Document\n",
        "\n",
        "import docx2txt\n",
        "from PyPDF2 import PdfReader\n",
        "import docx2txt  # Make sure to install docx2txt: pip install docx2txtG\n",
        "def read_text_from_docx(file_path):\n",
        "    try:\n",
        "        doc = docx2txt.process(file_path)\n",
        "        return doc\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading DOCX file '{file_path}': {e}\")\n",
        "        return None\n",
        "\n",
        "def read_text_from_pdf(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            pdf_reader = PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page_num in range(len(pdf_reader.pages)):\n",
        "                text += pdf_reader.pages[page_num].extract_text()\n",
        "            return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading PDF file '{file_path}': {e}\")\n",
        "        return None\n",
        "\n",
        "def read_text_from_doc(file_path):\n",
        "    try:\n",
        "        text = docx2txt.process(file_path)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading DOC file '{file_path}': {e}\")\n",
        "        return None\n",
        "\n",
        "def read_text_from_file(file_path):\n",
        "    # Determine the file type based on the extension\n",
        "    file_extension = os.path.splitext(file_path)[1].lower()\n",
        "\n",
        "    if file_extension == \".docx\":\n",
        "        return read_text_from_docx(file_path)\n",
        "    elif file_extension == \".pdf\":\n",
        "        return read_text_from_pdf(file_path)\n",
        "    elif file_extension == \".doc\":\n",
        "        return read_text_from_doc(file_path)\n",
        "    else:\n",
        "        print(f\"Unsupported file type for '{file_path}'\")\n",
        "        return None\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yHa3-K-R_l7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import json\n",
        "#keys_to_extract = ['Name','Contact Number','Email Id','Social Media Profile','Area of Interest','Technical Skills','Interpersonal Skills','Achievement','Educational Details','Internships','Previous Worked Projects','Work Experience']"
      ],
      "metadata": {
        "id": "KF79KmfC_nSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "07wRYmzA_ovn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(22,31):\n",
        "    folder_path = \"/content/drive/MyDrive/LLM Resume Extraction/Dataset Collection/new pdfs/\"+str(i)\n",
        "    folder_path = os.path.normpath(folder_path)\n",
        "    texts=[]\n",
        "    #extracts=[]\n",
        "    js=[]\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        if os.path.isfile(file_path):\n",
        "            text = read_text_from_file(file_path)\n",
        "            if text is not None:\n",
        "                extract = extraction(text,openai=openai)\n",
        "                if extract.startswith(\"{\") and extract.endswith(\"}\"):\n",
        "                  json_data=submit_request_gpt(json_promp,str(extract),openai=openai)\n",
        "                  js.append(json_data)\n",
        "                  #extracts.append(extract)\n",
        "                  texts.append(text)\n",
        "    json_data_modified = str(js).replace(\"\\\\\\\\n\", \"\").replace(\"\\\\\\\\\", \"\").replace('\\\\n', '').replace('\\\\', '').replace(\"'{\", \"{\").replace(\"}'\", \"}\").replace(\"!\", \"\")\n",
        "    data_list1 = json.loads(json_data_modified)\n",
        "    l=pd.DataFrame(data_list1)\n",
        "    lc = l[['Name', 'Contact Number', 'Email Id', 'Social Media Profile', 'Area of Interest', 'Technical Skills', 'Interpersonal Skills', 'Achievement', 'Educational Details', 'Internships', 'Previous Worked Projects', 'Previous Working Experience']]\n",
        "    lc['Resume Text']=texts\n",
        "    excel_path='/content/drive/MyDrive/LLM Resume Extraction/Dataset Collection/excel/'+str(i)+'.xlsx'\n",
        "    lc.to_excel(excel_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "id": "ThCanhfN_qMA",
        "outputId": "d913ede9-ae96-46fd-c3a5-f44821334dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Name': 'Akanksha Jha', 'Contact Number': '+91-9764996715', 'Email Id': 'akankshajha05@gmail.com', 'Social Media Profile': '', 'Area of Interest': '', 'Technical Skills': 'SAP, SuccessFactors, Dynamics 365 for HR, HP ALM, Xray testing tool, MS Excel', 'Interpersonal Skills': '', 'Achievement': 'Received Performance Award continuously for the three-year 2021, 2020, 2019', 'Educational Details': 'Executive MBA, 1st Division - 6.56 CGPA from AMITY UNIVERSITY\\nBSc Management, 1st Division - 3.58 GPA from WESTERN INTERNATIONAL UNIVERSITY\\nHigher Secondary, 1st Division - 63% from PATNA CENTRAL SCHOOL, CBSE', 'Internships': '', 'Previous Worked Projects': '', 'Previous Working Experience': 'Expert 2 – Sigma-Aldrich Chemicals Pvt Ltd, Bangalore\\nSpecialist - Bosch Global Software Technologies, Bangalore\\nSpecialist - Bosch Global Software Technologies, Bangalore\\nSr. Associate Consultant - Bosch Global Software Technologies, Bangalore\\nSr. Associate Consultant - Bosch Global Software Technologies, Bangalore\\nAssistant Manager - SGS People source Pvt. Ltd, Bangalore\\nSoftware Engineer - HCL Technologies, Noida', 'Profile Summary': '', 'Skills': '', 'Experiences': '', 'Active Certifications and Achievements': 'SAP SuccessFactors Compensation Management\\nSAP SuccessFactors Recruiting Management\\nSAP SuccessFactors Performance Management Goal Management'}\n",
            "{'Name': 'Abdul Hameed Mahuthannan', 'Contact Number': '+966 51 071 0951', 'Email Id': 'abdul.it11@gmail.com', 'Social Media Profile': 'abdul.it11', 'Area of Interest': 'SAP Technical Consultant', 'Technical Skills': 'S/4 HANA, ABAP on HANA, OData, UI5, Data Dictionary, Classical, Interactive, ALV Reports, Adobe Forms, Smart Forms, Scripts, BDC, LSMW, Module Pool Programming, Performance Tuning, Enhancements, User Exits, BADI, BAPI, EDI, ALE, RFC, Standard, Custom Debugging, New ABAP Debugger, ABAP Syntax 7.5, Debugger Scripting, Transport Request Management, HCM Ad-Hoc Queries', 'Interpersonal Skills': 'Excellent communication, presentation, time and team management skills', 'Achievement': 'Led an enthusiastic and effective tiny in-house development team', 'Educational Details': 'B.Tech - Information Technology | 2011 - 2015 | 80%', 'Internships': [{'Company': 'Capgemini Technology', 'Duration': 'August 2017 - January 2018', 'Project': 'SAP ECC 6 Rollout & Support', 'Skills Involved': 'ABAP RICEFW Objects'}, {'Company': 'Chennai Pulp & Paperboards Co', 'Duration': 'April 2015 - April 2017', 'Project': 'SAP Technical Support', 'Skills Involved': 'ABAP'}, {'Company': 'HCL Technologies', 'Duration': 'May 2019 - January 2022', 'Project': 'SAP ECC 6.7 Implementation & Support', 'Skills Involved': 'ABAP RICEFW Objects'}, {'Company': 'OTE Group of Companies', 'Duration': 'January 2018 - April 2019', 'Project': 'SAP Implementation& Support', 'Skills Involved': 'SAP ABAP, HR ABAP, CRM Technical, Fiori, OData'}], 'Previous Worked Projects': [{'Project Title': 'SAP S/4 HANA 1809 Implementation & Support', 'Duration': 'January 2022 to June 2022', 'Client': 'In-House Implementation Team', 'Role': 'SAP Senior Technical Consultant', 'Skills Involved': 'ABAP on HANA, Forms (Adobe Forms & Interactive Adobe Forms), Enhancements, Reports, CDS Views & Fiori Apps', 'SAP Environment': 'SAP S/4 HANA 1809', 'Functional Modules': 'SD, MM, HCM, FICO, PS & CS'}, {'Project Title': 'SAP Custom UI5 Application Implementation & Support', 'Duration': 'September 2022 to March 2023', 'Client': 'Saudi Aramco - Contractor(AEC)', 'Role': 'SAP Senior Technical Lead', 'Skills Involved': 'ABAP RICEFW Objects, OO ABAP, OData, UI5 & CDS Views', 'SAP Environment': 'SAP S/4 HANA 1909', 'Functional Modules': 'SCM & SAP Record Management(Organizer)'}, {'Project Title': 'SAP ABAP/HCM Go Live Support & Enhancements(ZATCA E-Invoice & BCM)', 'Duration': 'May 2023 to July 2023', 'Client': 'Mitsubishi Power SA - Full-time', 'Role': 'SAP Senior Techno Functional Consultant', 'Skills Involved': 'ABAP RICEFW Objects, OO ABAP, OData, HCM Saudi Payroll, TM, PA & OM', 'SAP Environment': 'SAP S/4 HANA 1909', 'Functional Modules': 'HCM, CPI & SuccessFactor'}], 'Previous Working Experience': [{'Company': 'Capgemini Technology', 'Duration': 'August 2017 - January 2018', 'Role': 'ABAP Consultant'}, {'Company': 'Chennai Pulp & Paperboards Co', 'Duration': 'April 2015 - April 2017', 'Role': 'Junior Analyst - SAP'}, {'Company': 'HCL Technologies', 'Duration': 'May 2019 - January 2022', 'Role': 'SAP ABAP Senior Consultant & Printer Vendor Program Support Consultant'}, {'Company': 'OTE Group of Companies', 'Duration': 'January 2018 - April 2019', 'Role': 'SAP ABAP Consultant'}]}\n",
            "{'Name': 'Akanksha Kaushik', 'Contact Number': '9582772177', 'Email Id': 'akankshakaushikit3004@gmail.com', 'Social Media Profile': '', 'Area of Interest': '', 'Technical Skills': 'SAP BCS/BPC Consultant, BI/BW/HANA consultant, Data Modelling, Master data maintenance, Process Chain Management, Consolidation workbench', 'Interpersonal Skills': 'Quick Learner, good communication skills', 'Achievement': '', 'Educational Details': 'Post-Graduation Diploma in Advance Computing (PG-DAC) from Centre of Development of Advance Computing with 66%, Bachelor of Technology in Information Technology from United College of Engineering and Research, Allahabad with 65.32%', 'Internships': '', 'Previous Worked Projects': 'BCS-Production (Deutsche Bank): Global General Ledger Consolidation and Reporting (GGLCAR)', 'Previous Working Experience': 'SAP BCS/BPC Consultant at HCL Technologies Ltd (08/03/2017- Present), SAP BCS Consultant at HCL Technologies Ltd (04/02/2015–07/03/2017)'}\n",
            "{'Name': 'Akansha Srivastava', 'Contact Number': '+91-9199790204 / 9999801461', 'Email Id': 'akansha.srivastavait@gmail.com', 'Social Media Profile': None, 'Area of Interest': 'IT-SERVICE MANAGEMENT, Service Delivery Lead, Service introduction, Change Management, Release Management, Application Development, Support and Enhancement', 'Technical Skills': 'ITIL, ITSM, SAP, SDLC, STLC, UAT, INTEGRATION TESTING, Performance testing, Networking, TCP/IP, ServiceNow, Gcharm, Jira, RevTrac, ASP.net, C', 'Interpersonal Skills': 'Hardworking, Determined, Excellent Analytical skills, Capable of performing well under 24x7 business environment', 'Achievement': None, 'Educational Details': 'Bachelor of Technology (Information and Technology Engineering) from Uttar Pradesh Technical University, Lucknow in 2014', 'Internships': None, 'Previous Worked Projects': None, 'Previous Working Experience': 'ITIL senior consultant at Ernst & Young LLP (February 2019 till date)\\nChange Manager at IBM India Pvt Ltd (January 2015 till January 2019)'}\n",
            "{'Name': 'Akansha Srivastava', 'Contact Number': '+91-9199790204 / 9999801461', 'Email Id': 'akansha.srivastavait@gmail.com', 'Social Media Profile': None, 'Area of Interest': 'IT-SERVICE MANAGEMENT, Service Delivery Lead, Service introduction, Change Management, Release Management, Application Development, Support and Enhancement', 'Technical Skills': 'ITIL, ITSM, SAP, SDLC, STLC, UAT, INTEGRATION TESTING, Performance testing, Networking, TCP/IP, ServiceNow, Gcharm, Jira, RevTrac, ASP.net, C', 'Interpersonal Skills': 'Hardworking, Determined, Excellent Analytical skills, Capable of performing well under 24x7 business environment', 'Achievement': None, 'Educational Details': 'Bachelor of Technology (Information and Technology Engineering) from Uttar Pradesh Technical University, Lucknow in 2014', 'Internships': None, 'Previous Worked Projects': None, 'Previous Working Experience': 'ITIL senior consultant at Ernst & Young LLP (February 2019 till date)\\nChange Manager at IBM India Pvt Ltd (January 2015 till January 2019)'}\n",
            "{'Name': 'Akansha Srivastava', 'Contact Number': '+91-9199790204 / 9999801461', 'Email Id': 'akansha.srivastavait@gmail.com', 'Social Media Profile': None, 'Area of Interest': 'IT-SERVICE MANAGEMENT, Service Delivery Lead, Service introduction, Change Management, Release Management, Application Development, Support and Enhancement', 'Technical Skills': 'ITIL, ITSM, SAP, SDLC, STLC, UAT, INTEGRATION TESTING, Performance testing, Networking, TCP/IP, ServiceNow, Gcharm, Jira, RevTrac, ASP.net, C', 'Interpersonal Skills': 'Hardworking, Determined, Excellent Analytical skills, Capable of performing well under 24x7 business environment', 'Achievement': None, 'Educational Details': 'Bachelor of Technology (Information and Technology Engineering) from Uttar Pradesh Technical University, Lucknow in 2014', 'Internships': None, 'Previous Worked Projects': None, 'Previous Working Experience': 'ITIL senior consultant at Ernst & Young LLP (February 2019 till date)\\nChange Manager at IBM India Pvt Ltd (January 2015 till January 2019)'}\n",
            "{'Name': 'Akansha Srivastava', 'Contact Number': '+91-9199790204 / 9999801461', 'Email Id': 'akansha.srivastavait@gmail.com', 'Social Media Profile': None, 'Area of Interest': 'IT-SERVICE MANAGEMENT, Service Delivery Lead, Service introduction, Change Management, Release Management, Application Development, Support and Enhancement', 'Technical Skills': 'ITIL, ITSM, SAP, SDLC, STLC, UAT, INTEGRATION TESTING, Performance testing, Networking, TCP/IP, ServiceNow, Gcharm, Jira, RevTrac, ASP.net, C', 'Interpersonal Skills': 'Hardworking, Determined, Excellent Analytical skills, Capable of performing well under 24x7 business environment', 'Achievement': None, 'Educational Details': 'Bachelor of Technology (Information and Technology Engineering) from Uttar Pradesh Technical University, Lucknow in 2014', 'Internships': None, 'Previous Worked Projects': None, 'Previous Working Experience': 'ITIL senior consultant at Ernst & Young LLP (February 2019 till date)\\nChange Manager at IBM India Pvt Ltd (January 2015 till January 2019)'}\n",
            "{'Name': 'Akansha Srivastava', 'Contact Number': '+91-9199790204 / 9999801461', 'Email Id': 'akansha.srivastavait@gmail.com', 'Social Media Profile': None, 'Area of Interest': 'IT-SERVICE MANAGEMENT, Service Delivery Lead, Service introduction, Change Management, Release Management, Application Development, Support and Enhancement', 'Technical Skills': 'ITIL, ITSM, SAP, SDLC, STLC, UAT, INTEGRATION TESTING, Performance testing, Networking, TCP/IP, ServiceNow, Gcharm, Jira, RevTrac, ASP.net, C', 'Interpersonal Skills': 'Hardworking, Determined, Excellent Analytical skills, Capable of performing well under 24x7 business environment', 'Achievement': None, 'Educational Details': 'Bachelor of Technology (Information and Technology Engineering) from Uttar Pradesh Technical University, Lucknow in 2014', 'Internships': None, 'Previous Worked Projects': None, 'Previous Working Experience': 'ITIL senior consultant at Ernst & Young LLP (February 2019 till date)\\nChange Manager at IBM India Pvt Ltd (January 2015 till January 2019)'}\n",
            "{'Name': 'Akansha Srivastava', \n",
            "'Contact Number': '+91 9168667583', \n",
            "'Email Id': 'akanshasrivastav137@gmail.com', \n",
            "'Social Media Profile': 'linkedin.com/in/akansha-srivastav-068952a0', \n",
            "'Area of Interest': 'human resources transformation and management with focus on the SuccessFactors solutions', \n",
            "'Technical Skills': 'Successfactor Recruiting Management, Successfactor Recruiting Marketing, Communication Skills, SuccessFactors Onboarding 2.0, Successfactors Reporting, People Analytics, Oracle Taleo recruitment and onboarding', \n",
            "'Interpersonal Skills': 'Initiative-taking, dedicated, detail-oriented', \n",
            "'Achievement': 'Vodafone Star Award ‘ 2018 (Q3), Vodafone Star Award ‘ 2019 (Q4), Best Debutant Award Volkswagen (2020)', \n",
            "'Educational Details': 'Bachelors of Engineering- CSE, Marathwada Institute of Technology, Aurangabad, HSC, Deogiri College, Aurangabad, SSC, St Lawrence High School, Aurangabad', \n",
            "'Internships': 'PwC India, Pune', \n",
            "'Previous Worked Projects': 'Multiple Country Implementation for a Cloud & Digital Consulting Client, Recruiting Management and Marketing Implementation for a Manufacturing Client, Implementation for a Auto-Mobile based Client, Volkswagen AG SF Implementation (Success factor RCM & RMK Lead), Volkswagen India SF Support Onboarding 2.0, Implementation of Successfactor Recruitment & Recruiting Marketing module in Vodafone, TALEO (Oracle product for recruiting) Implementation of Taleo in new countries Ghana, Mozambique, Tanzania', \n",
            "'Previous Working Experience': 'Senior Consultant Sep 2021 - Present, PwC India, Pune, Senior Software Engineer Feb 2020 - Sep 2021, Volkwagen IT Sevices, Pune, Deputy Manager May 2015 - Jan 2020, Vodafone India, Pune'}\n",
            "{'Name': 'Akansha', 'Contact Number': '7406518902', 'Email Id': 'akanshasinha09@gmail.com', 'Social Media Profile': '', 'Area of Interest': 'Finance and Accounts', 'Technical Skills': 'SAP Banking', 'Interpersonal Skills': 'Strong leadership, motivational skills, ability to set own priorities, organized, analytical and problem-solving skills, excellent communication, ability to handle a team, ability to work under pressure, knowledge of MS-Excel and MS Office', 'Achievement': 'Awarded for demonstrating the SAP behavior \"Keep the Promise and Build Bridges not Silos, for achieving desire target S/4 HANA OP Banking Test', 'Educational Details': 'Pursuing PGDBM-BFM (MBS in Banking and Finance) from NMIMS (2020-2022), B-Tech in Electronics and Communication from Rajasthan Technical University with 72% (2013), Intermediate from St. Michaels High School, Patna with 74% (2009), SSC from St. Dominic Savio’s High School, Patna with 87% (2007)', 'Internships': 'Accenture Pvt Ltd (July 2018 – Oct 2020) - Project title: SAP Account Management - Banking and Finance, SAP Labs India Pvt Ltd (Oct 2014 – July 2017) - Project title: SAP Collateral Management - Banking and Finance', 'Previous Worked Projects': '', 'Previous Working Experience': 'Accenture Pvt Ltd (July 2018 – Oct 2020) - Project title: SAP Account Management - Banking and Finance, SAP Labs India Pvt Ltd (Oct 2014 – July 2017) - Project title: SAP Collateral Management - Banking and Finance'}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-75d4ff6a4bd5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                   \u001b[0mtexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mjson_data_modified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\\\\\\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\\\\\\\\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\\\'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'{\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"}'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdata_list1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_data_modified\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mlc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Contact Number'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Email Id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Social Media Profile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Area of Interest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Technical Skills'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Interpersonal Skills'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Achievement'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Educational Details'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Internships'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Previous Worked Projects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Previous Working Experience'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting ',' delimiter: line 1 column 13472 (char 13471)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z4brkHOCmQ_",
        "outputId": "da2e5eb9-b494-47e9-f32a-9f66b54ed3fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bKZr5Nzb_rhe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}